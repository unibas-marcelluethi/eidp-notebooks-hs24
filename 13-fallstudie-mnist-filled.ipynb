{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6LiuoBdqDhI"
   },
   "source": [
    "# Fallstudie - Der Computer lernt Zahlen zu lesen\n",
    "Wir wollen heute schauen, was wir mit unseren Python-Kenntnissen alles schon tun können. Als Beispiel wollen wir dem Computer Lesen beibringen und überprüfen wie gut er das dann auch macht. Etwas genauer soll der Computer von Hand geschriebene Ziffern erkennen können. Eine bekannte Sammlung solcher Ziffern ist die MNIST Datenbank. Einige Beispiele der Zahlen sind hier:\n",
    "\n",
    "![Images von der MNIST Datenbank](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "> Bild von [Wikipedia](https://de.wikipedia.org/wiki/MNIST-Datenbank)\n",
    "\n",
    "Wir werden dazu eine Technik aus dem Maschinellen Lernen einsetzen, die unter dem Namen Deep Learning bekannt ist. Deep Learning revolutioniert seit einigen Jahren die Informatik. Entsprechend gibt es viele Bibliothken, die wir nutzen können. Wir können also auf dem aufbauen, was andere schon programmiert haben.\n",
    "\n",
    "Wir verwenden heute überwiegend Keras von Tensorflow, ein Deep-Learning Framework, also eine Bibliothek welche die gesamte Funktionalität mibringt, die wir benötigen um Deep Learning umzusetzen. Zudem verwenden wir noch die Bibliotheken welche Sie sich im Selbststudium angeschaut haben.\n",
    "\n",
    "Auch wenn wir für die Aufgabe heute nicht genau verstehen müssen wie Deep-Learning funktioniert, hier ein kurzer Überblick.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5S1Ytb2ukgX"
   },
   "source": [
    "\n",
    "# Deep-Learning kurz erklärt\n",
    "\n",
    "Die wichtigste Komponente beim Deep learning ist ein sogenanntes neuronales Netz (NN). Wir wollen ein neuronales Netz verwenden um für ein Bild einer Ziffer, die darin gezeigte Ziffer vorher zu sagen. Das neuronale Netz stellt dabei die Bilder numerisch dar und transformiert die Daten, bis die Entscheidung zu welcher Klasse eine Eingabe gehört ganz einfach wird. Grafisch können wir das wie folgt skizzieren:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1NDIZo9ovJOIKd-wCLzfQNk6NJzUsFpN6\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Unser Model wird jedoch etwas anders funktionieren. Das Bild wird als ein langer Vektor, also ein 1D-Array von Zahlen, in das Netz gefüttert. Zudem ist die Vorhersage in unserem Fall nicht nur eine Zahl, sondern ein 1D-Array von zehn Zahlen. Dabei gibt jede Zahl an, welche Ziffer wie wahrscheinlich in dem Bild vorkommt. Die erste Zahl gibt an, wie wahrscheinlich die Ziffer im Bild eine Null ist, die zweite Zahl gibt an, wie wahrscheinlich die Ziffer eine 1 ist, und so weiter. Unser Bild ist also wie folgt schon etwas genauer:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1Q3lMOMVbgTXOVasNd4O5w0gSIsk7XSoX\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Im Innern eines solchen Models gibt es meist einen oder mehrere Layers. Im Namen *Deep-Learning* steckt, dass das Model mehrere Layer \"tief\" ist.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1_OXD0SsTDI0sr3Noro8WPkWAGkGJubG9\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Für diese Fallstudie wollen wir nicht wissen was genau in den Layern passiert, wer will kann einfach an eine grosse Matrixmultiplikation denken. Diese Layer haben Parameter, oft auch Weights genannt, welche wir während dem Lernen, auch Training genannt, anpassen.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1Z5bUK4lIS7dVOpWXfAs-uE4e1XGqZPXx\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Die Veränderung geschieht mit Hilfe eines Optimierers. Der Optimierer berechnet ein Update für die Gewichte basierend auf dem Fehler, welcher unser Model bei der Vorhersage macht. Der Fehler wird basierend auf der Vorhersage und den wahren Labels durch eine Fehler- oder Loss-Funktion gemessen.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1v0LjwSUigxN1_ureTIsdtXo-Gh-KJITe\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Wir wollen von sehr vielen Bildern lernen. Um dies effizient zu machen, können wir, vorallem auf Grafikkarten, mehrere Bilder auf einmal durch unser neuronales Netz schicken und erhalten für jedes der Bilder eine eigene Antwort. Wir nennen einen solchen Stapel von Bildern welcher auf einmal durch das Netz geschickt wird auch *Batch*.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://drive.google.com/uc?id=1iO7NVINIdPexi8X-gk4GsmLQ1u2iTkUV\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "So nun haben wir viel über Deep-Learning gelernt und wollen uns diese Sachen in Python anschauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYDhCa4xFcrA"
   },
   "source": [
    "## Vorbereitungen und Daten\n",
    "\n",
    "Wir verwenden hier exemplarisch das Framework Keras, was Teil der Tensorflow Bibliothek ist. Als erstes importieren wir dies. Dass wir nicht jedesmal wenn wir das Jupyter-Notebook erneut ausführen, zufällig ein leicht anderes Resultat bekommen, starten wir immer mit der selben Zufallszahl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJBKYVxRWa2f"
   },
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lt0bIt2XFvar"
   },
   "source": [
    "Nun wollen wir uns die Daten zurecht legen. Wir können die MNIST Daten mit einem einfachen Befehl in das Notebook laden. Wir unterscheiden hier Trainings- und Testdaten. Erstere sind dazu da das Model zu trainieren und damit besser zu machen. Die Testdaten sind danach dazu da, zu schauen wie gut das Model durch das Training geworden ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVKb2GQxOu3A",
    "outputId": "a971647e-5e94-4afb-9b9b-0ca394edacb2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gTm_xGGF3v0"
   },
   "source": [
    "Die Daten sind sogenannte Tensoren, diese können Sie sich wie die Arrays von Numpy vorstellen. Tensoren bieten auch viele zu Numpy Array identische Methoden an.\n",
    "\n",
    "Wir wollen nun anschauen, wieviele Daten wir geladen haben. Dafür können wir das Attribut `shape` verwenden. Dieses haben Sie schon im Selbstudium kennen gelernt. Das Attribut gibt an, wieviele Elemente das Array entlang jeder Dimension hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGkBzEEHOyeT",
    "outputId": "554d2911-a978-4d11-f1b2-ffe9f8173374"
   },
   "outputs": [],
   "source": [
    "print(\"the shape of the training images:\", train_images.shape)\n",
    "print(\"the space of the training labels:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M20G-kWHSoM"
   },
   "source": [
    "Wie wir sehen, haben wir 60000 Bilder für das Training zur Verfügung. Jedes Bild hat die grösse $28\\times 28$ pixel. Die Bilder enthalten keine Farben, nur Graustufen.\n",
    "\n",
    "Wir wollen als nächstes einmal das erste Bild anschauen und das erste Label, also die Information welche Zahl im Bild zu sehen ist, ausgeben. Dafür schreiben wir uns eine Funktion welche das i-te Element der Trainingsdaten mit Hilfe von Pyplot anzeigt und im Titel das Label hinzu schreibt.\n",
    "\n",
    "Dann rufen wir die Methode mit dem Parameter `0` für das erste Bild auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "_qT7h4qMO84b",
    "outputId": "ad25dbac-dd13-49ac-c762-bab4883e38c7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(i):\n",
    "  image = train_images[i,:,:] # TODO: assign the i-th image from train_images\n",
    "  label = train_labels[i] # TODO: assign the i-th label from train_labels\n",
    "  # we use the color-map (cm) binary in order to see the numbers as\n",
    "  # black-on-white and not white-on-black.\n",
    "  plt.imshow(image, cmap=plt.cm.binary)\n",
    "  plt.title('the image has the label ' + str(label))\n",
    "\n",
    "show_image(0) # TODO: call the function show_image to show the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txiDwoIpIXyW"
   },
   "source": [
    "Als letzten Schritt mit den Daten wollen wir diese noch so aufbereiten, dass unser Model diese besser verwenden kann. Wir haben besprochen, dass das neuronale Netz jedes Bild als langen Vektor, also als 1D-Array, und nicht als Matrix, bzw. 2d-Array entgegen nimmt. Wir können dafür die Methode `reshape` verwenden, welche als Argument ein Tupel mit den neuen Dimensionen entgegen nimmt. Dabei müssen wir beachten, dass wir die gesamte Anzahl Elemente nicht verändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WyCsoWcSAuN",
    "outputId": "a4a79523-7231-4783-d196-80c023b9a39a"
   },
   "outputs": [],
   "source": [
    "train_images_input = train_images.reshape((60000, 28*28)) # TODO: reshape the train images\n",
    "test_images_input = test_images.reshape((10000, 28*28)) # TODO: reshape the test images\n",
    "\n",
    "# scaling of the values of the pixels into  0..1, usually helps when training\n",
    "train_images_input = train_images_input.astype(\"float32\") / 255\n",
    "test_images_input = test_images_input.astype(\"float32\") / 255\n",
    "\n",
    "train_images_input.shape # TODO: check the shape of the training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyyYc36BJTT9"
   },
   "source": [
    "## Das Neuronale Netz\n",
    "\n",
    "Als nächstes wollen wir ein neuronales Netz bauen. Dazu erstellen wir die einzelnen Layer und fügen diese dann in einer Reihe zu einem Model zusammen. Die Details müssen Sie nicht verstehen. Es reicht wenn Sie sehen, dass wir verschiedene Elemente zu etwas grösserem kombinieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvTD2FLIPePa"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "layer1 = layers.Dense(512, activation=\"relu\")\n",
    "# relu is a function with a kink at 0 like the following sketch: _/\n",
    "\n",
    "outputLayer = layers.Dense(10, activation=\"softmax\")\n",
    "# softmax normalizes the values between 0.0 and 1.0, such that they sum to 1\n",
    "\n",
    "model = keras.Sequential([\n",
    "  layer1,\n",
    "  outputLayer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqs4QwmYKx_Q"
   },
   "source": [
    "Als nächstes müssen wir dem Model noch sagen, welchen Optimierungsalgorithmus wir nutzen wollen, welche Fehlerfunktion wir optimieren wollen und wie wir die Güte des Models messen. Darauf gehen wir hier nicht näher ein, sondern verwenden einfach das folgende."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8cvoUBkKNG_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"rmsprop\",\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqWrTu2MLQ0Z"
   },
   "source": [
    "Nun können wir unser Model trainieren. Dazu verwenden wir die Methode `fit`. Diese bekommt die Bilder und Labels fürs Training. Zusätzlich geben wir noch an wieviele Epochen `epochs` wir trainieren, also wie oft wir alle Trainingsdaten durch unser Model schicken. Als letzts geben wir noch an wie gross die Batchgrösse `batch_size` ist, also wieviele Bilder wir auf einmal durch unser Netzwerk schicken. Zurück bekommen wir den Verlauf des Trainings. Den wir danach visualisieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkUiAIr6SVMc",
    "outputId": "a92c9d9c-64fb-44d6-ec46-cd671a15743e"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images_input,train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud054c-Ru8A0"
   },
   "source": [
    "Wir können nun anschauen wie das Netzwerk lernt, also wie es mit der Zeit immer weniger Fehler macht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "_ze_NBQ4MIap",
    "outputId": "daa62242-bed5-4fc7-cd86-7ebdec35687f"
   },
   "outputs": [],
   "source": [
    "history.history.keys()\n",
    "evolution_of_loss_values = history.history[\"loss\"]\n",
    "evolution_of_loss_values\n",
    "plt.plot(evolution_of_loss_values) # TODO: simply plot the values to see it graphically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDhJ_KKSNvWA"
   },
   "source": [
    "Noch bis vor dem Training war dem Model nicht klar wie gross die Eingabedaten sind. Deshalb konnten wir auch noch nicht schauen wie unser Netzwerk genau aussieht. Nun da die Grösse der Daten welche wir dem Netzwerk füttern bekannt ist, können wir schauen wie unser Model ausschaut und wieviele Parameter, also einzelne Zahlen wir gelernt haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTB3L-wWNllD",
    "outputId": "9c6129a9-eeac-41b6-fcca-922b88dc4cbf"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhLHLqfVxijJ"
   },
   "source": [
    "Sie sehen, wir haben in diesem einfachen Model schon fast eine halbe Million Parameter. Grosse Netze welche in realen Szenarien angewendet werden, haben dann oft noch viel mehr Parameter. Diese da sie oft viel tiefer sind, also aus mehr Layern bestehen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol7QF9j6sOms"
   },
   "source": [
    "## Testen und Analysieren\n",
    "\n",
    "Nachdem das Netzwerk trainiert ist, wollen wir nun untersuchen wie gut unser Model neue Ziffern, welche nicht während dem Training gesehen wurden, klassifiziert werden können.\n",
    "\n",
    "Dafür schauen wir zuerst an, wie wir unser Model verwenden können und was es für ein Bild der Testdaten zurück gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdbxP10aSb2q",
    "outputId": "af5d7267-6d1a-46f4-a741-a31c28b0d2bd"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images_input)\n",
    "print(predictions.shape) # TODO: show the size of the tensor\n",
    "print('Vorhersage für das erste Bild',predictions[0,:]) # TODO: print the prediction for the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSVo6JwrLI6c"
   },
   "source": [
    "Für jedes Bild bekommen wir eine Wahrscheinlichkeit pro Ziffer. Diese gibt an wie wahrscheinlich es die jeweilige Ziffer ist. Wir können mit der Methode `argmax()` schauen, welches die Ziffer ist, die nach der Meinung unseres Netzes am wahrscheinlichsten im Bild vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScYEnFO-LJWk",
    "outputId": "89b8b630-adb1-4b69-f057-bc73807a4488"
   },
   "outputs": [],
   "source": [
    "predicted = predictions.argmax(axis=1)\n",
    "print('Vorhergesagte Ziffer für das erste Bild', predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0nb5gh7Lt0a"
   },
   "source": [
    "\n",
    "Für die Visualisierung der Vorhersage können wir uns erneut eine Funktion schreiben. Dies können wir analog zu der Funktion machen, welche wir verwendet haben um die Trainingsdaten anzuzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "msu-LxDwS0IB",
    "outputId": "6e819165-cf76-4613-89c5-488e19e9f6fc"
   },
   "outputs": [],
   "source": [
    "def show_prediction(i):\n",
    "  image = test_images[i,:,:] # TODO: assign image\n",
    "  gt_label = test_labels[i] # TODO: assign the test label\n",
    "  predicted_label = predicted[i] # TODO: assign the predicted label\n",
    "  plt.imshow(image, cmap=plt.cm.binary)\n",
    "  plt.title(\"image {} : label {} prediction {}\".format(i,gt_label, predicted_label))\n",
    "  plt.show()\n",
    "\n",
    "show_prediction(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESN7V-Cts7n5"
   },
   "source": [
    "\n",
    "Nun können wir schauen ob wir öfters das richtige Label vorher sagen. Dafür schauen wir uns einmal die ersten 20 Vorhersagen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R0iy7d0Sw0j",
    "outputId": "9a7886c2-e652-41ee-d5bf-a5f9307e392d"
   },
   "outputs": [],
   "source": [
    "# TODO: print the first 20 training labels and predicted labels\n",
    "for i in range(0,20):\n",
    "  print(\"image {} : label {} preduction {}\".format(i,test_labels[i], predicted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWR6H1--sJK7"
   },
   "source": [
    "Machen wir wirklich keine Fehler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ezbKUPjcLsUb",
    "outputId": "f89a2617-94d4-4537-f017-c14fb34e2bb1"
   },
   "outputs": [],
   "source": [
    "show_prediction(247)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWdSYYoavi1d"
   },
   "source": [
    "Um das Netzwerk mit allen Testdaten zu evaluieren, gibt es schon eine Evaluationsmethode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jh8v7OdQvr2m",
    "outputId": "a3bcc643-2b85-4f52-e921-95e95834fbc0"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_input, test_labels)\n",
    "print('test_acc: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trcyG5gQrZrq"
   },
   "source": [
    "## Fehlerfälle Visualisieren\n",
    "\n",
    "Wir zeigen nun noch alle Fehlerfälle an. Können Sie die Fehler nachvollziehen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "zWrm-8HNWtTx",
    "outputId": "2f78944c-f62a-4a3e-906b-d53b080d9dcd"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: show prediction for error cases in a loop (add two lines to your loop)\n",
    "for i in range(0,test_labels.size):\n",
    "  if not test_labels[i] == predicted[i]:\n",
    "    show_prediction(i)\n",
    "    IPython.display.clear_output(wait=True) # necessary to update the image\n",
    "    time.sleep(2) # wait for 2 seconds before you continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX40P2bz7sO1"
   },
   "source": [
    "## Miniübungen\n",
    "- Trainieren Sie das Model für mehr Iterationen.\n",
    "- Erweitern Sie das Model und fügen Sie mehr Layer ein. Reduzieren sich die Fehler im Testset mit mehr Layern?\n",
    "- Fügen Sie nach jedem `Dense`-Layer, ausser dem Output-Layer, einen Layer ein welchen Sie mit `layers.Dropout(0.2)` erstellen.\n",
    "- Wenn Sie wollen können Sie nun noch etwas genauer analysieren ob das Netzwerk gewisse Ziffern öfters verwechselt als andere. Dafür können Sie für jedes Label anschauen wie oft welche andere Ziffer falsch vorhergesagt wird. Wenn Sie dies in eine Numpy Array speichern, können Sie das Ergebnis mit Pyplot plotten. Dafür starten Sie mit einem zweidimensionalen Numpy Array gefüllt mit Nullen. Bei jedem Fehler erhöhen Sie die Zahl im Array an der Stelle (gt_label,prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "777NezKpZ7ED"
   },
   "outputs": [],
   "source": [
    "layer1 = layers.Dense(512, activation=\"relu\")\n",
    "layer2 = layers.Dense(512, activation=\"relu\")\n",
    "dropout = layers.Dropout(0.2) # simulates missing/noisy data\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "  layer1,\n",
    "  dropout,\n",
    "  layer2,\n",
    "  dropout,\n",
    "  outputLayer\n",
    "])\n",
    "\n",
    "model2.compile(\n",
    "  optimizer=\"rmsprop\",\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model2.fit(train_images_input,train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "predictions = model.predict(test_images_input)\n",
    "\n",
    "predicted = predictions.argmax(axis=1)\n",
    "\n",
    "show_prediction(247)\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(test_images_input, test_labels)\n",
    "print('test_acc: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KWen0CwWpdh",
    "outputId": "3e8f0fe0-3fea-446d-b129-a661f10bc5e4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "error_counter = 0\n",
    "confusion_errors_matrix = np.zeros(shape = [10,10])\n",
    "\n",
    "for i in range(0,10000):\n",
    "  label = test_labels[i]\n",
    "  prediction = predicted[i]\n",
    "  if not label == prediction:\n",
    "    error_counter += 1\n",
    "    confusion_errors_matrix[label,prediction] += 1\n",
    "    print('\\r','E{} I{} : label {} prediction {}'.format(error_counter, i, label, prediction))\n",
    "  else:\n",
    "    print('\\r','I{} : label {} prediction {}'.format(i, label, prediction), end='')\n",
    "print()\n",
    "print('the network had {} errors out of 10000'.format(error_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNnfXReTrxII"
   },
   "source": [
    "Wir schauen an welche Kombinationen von Label-Prediction die meisten Fehler erzeugt. Dies gibt ein Hinweis, was für das Netzwerk schwer zu lernen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "_Q36F1atlJ8t",
    "outputId": "4b3aa4ab-9dc1-45a9-a512-5a02de835263"
   },
   "outputs": [],
   "source": [
    "plt.imshow(confusion_errors_matrix)\n",
    "plt.ylabel('label')\n",
    "plt.xlabel('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TMk29FNV21E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "r6LiuoBdqDhI"
   ],
   "name": "mnist-fallstudie-complete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
